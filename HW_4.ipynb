{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "HW_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DkInjXpgqja"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ9t4l2egqjc"
      },
      "source": [
        "with open('/content/drive/MyDrive/Geekbrainst/preprocessed_tweets.pkl', 'rb') as f:\n",
        "    df = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY5Rm8kYgqjd",
        "outputId": "b508ce9b-382f-4c5b-cd2c-5c8c2df23c95"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
              "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
              "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>[bihday, your, majesty]</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "      <td>[bihday, majesti]</td>\n",
              "      <td>[bihday, majesti]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love yoyou take with yoyou all the time ...</td>\n",
              "      <td>[model, love, yoyou, take, with, yoyou, all, t...</td>\n",
              "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
              "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
              "      <td>[model, love, yoyou, take, yoyou, time, yoyour]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society now motivation</td>\n",
              "      <td>[factsguide, society, now, motivation]</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "      <td>[factsguid, societi, motiv]</td>\n",
              "      <td>[factsguid, societi, motiv]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  \\\n",
              "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
              "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
              "2   3    0.0                                bihday your majesty   \n",
              "3   4    0.0  #model   i love u take with u all the time in ...   \n",
              "4   5    0.0             factsguide: society now    #motivation   \n",
              "\n",
              "                                         clean_tweet  \\\n",
              "0  when father is dysfunctional and is so selfish...   \n",
              "1  thanks for lyft credit cannot use cause they d...   \n",
              "2                                bihday your majesty   \n",
              "3  model love yoyou take with yoyou all the time ...   \n",
              "4                  factsguide society now motivation   \n",
              "\n",
              "                                         tweet_token  \\\n",
              "0  [when, father, is, dysfunctional, and, is, so,...   \n",
              "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
              "2                            [bihday, your, majesty]   \n",
              "3  [model, love, yoyou, take, with, yoyou, all, t...   \n",
              "4             [factsguide, society, now, motivation]   \n",
              "\n",
              "                                tweet_token_filtered  \\\n",
              "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
              "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
              "2                                  [bihday, majesty]   \n",
              "3    [model, love, yoyou, take, yoyou, time, yoyour]   \n",
              "4                  [factsguide, society, motivation]   \n",
              "\n",
              "                                       tweet_stemmed  \\\n",
              "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
              "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
              "2                                  [bihday, majesti]   \n",
              "3    [model, love, yoyou, take, yoyou, time, yoyour]   \n",
              "4                        [factsguid, societi, motiv]   \n",
              "\n",
              "                                    tweet_lemmatized  \n",
              "0  [father, dysfunct, selfish, drag, kid, dysfunc...  \n",
              "1  [thank, lyft, credit, use, caus, offer, wheelc...  \n",
              "2                                  [bihday, majesti]  \n",
              "3    [model, love, yoyou, take, yoyou, time, yoyour]  \n",
              "4                        [factsguid, societi, motiv]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJch5Vyygqje"
      },
      "source": [
        "# Задание 1.\n",
        "\n",
        "Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000)\n",
        "\n",
        "С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n",
        "    \n",
        "Повторим шаги из заданий 1 и 2, используя библиотеку nltk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6otDZENmgqje",
        "outputId": "6e7f9f98-61fb-45a4-e3d6-83fc1782f352"
      },
      "source": [
        "!pip install -U spacy\n",
        "import spacy\n",
        "from spacy import displacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "  Downloading spacy-2.3.2-cp38-cp38-win_amd64.whl (9.5 MB)\n",
            "Collecting wasabi<1.1.0,>=0.4.0\n",
            "  Downloading wasabi-0.8.0-py3-none-any.whl (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.2-cp38-cp38-win_amd64.whl (20 kB)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (49.2.0.post20200714)\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "  Downloading preshed-3.0.2-cp38-cp38-win_amd64.whl (115 kB)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.47.0)\n",
            "Collecting blis<0.5.0,>=0.4.0\n",
            "  Downloading blis-0.4.1-cp38-cp38-win_amd64.whl (5.0 MB)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.2-cp38-cp38-win_amd64.whl (181 kB)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.18.5)\n",
            "Collecting thinc==7.4.1\n",
            "  Downloading thinc-7.4.1-cp38-cp38-win_amd64.whl (2.1 MB)\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.3-cp38-cp38-win_amd64.whl (33 kB)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Installing collected packages: wasabi, murmurhash, cymem, preshed, blis, srsly, catalogue, plac, thinc, spacy\n",
            "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.3.2 srsly-1.0.2 thinc-7.4.1 wasabi-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0VIZIT2gqjf",
        "outputId": "fd2a3d84-717e-4b67-a9a1-08d4942858fc"
      },
      "source": [
        "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n",
        "import en_core_web_md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz (96.4 MB)\n",
            "Requirement already satisfied: spacy>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from en-core-web-md==2.2.0) (2.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.24.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (7.4.1)\n",
            "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (49.2.0.post20200714)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (4.47.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (1.25.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.4)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py): started\n",
            "  Building wheel for en-core-web-md (setup.py): finished with status 'done'\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.0-py3-none-any.whl size=98072937 sha256=ab049d3c39f07baf5aaf29378c560d7201fc8242b3dcd18ced7fbc0580251d0f\n",
            "  Stored in directory: c:\\users\\a.kraev\\appdata\\local\\pip\\cache\\wheels\\31\\1f\\21\\52bc46cea1e50c10a3b246d5d266455b9a0e77c380bb7ac928\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_md' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS9z50Z5gqjf",
        "outputId": "a49b1fe6-5b48-4101-a00b-629142d24a3f"
      },
      "source": [
        "%%time\n",
        "\n",
        "nlp = en_core_web_md.load()\n",
        "\n",
        "ner = df['clean_tweet'].apply(lambda x:  nlp(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 6min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJBuzMLbgqjg",
        "outputId": "395909e3-d044-4ed2-b06d-106d36a86a1b"
      },
      "source": [
        "ner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        (when, father, is, dysfunctional, and, is, so,...\n",
              "1        (thanks, for, lyft, credit, can, not, use, cau...\n",
              "2                                  (bihday, your, majesty)\n",
              "3        (model, love, yoyou, take, with, yoyou, all, t...\n",
              "4                   (factsguide, society, now, motivation)\n",
              "                               ...                        \n",
              "49154    (thought, factory, leftright, polarisation, tr...\n",
              "49155    (feeling, like, mermaid, hairflip, neverready,...\n",
              "49156    (hillary, campaigned, today, in, ohioomg, used...\n",
              "49157    (happy, at, work, conference, right, mindset, ...\n",
              "49158    (my, song, so, glad, free, download, shoegaze,...\n",
              "Name: clean_tweet, Length: 49159, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Ae-B42gqjg"
      },
      "source": [
        "ner_list = ner.tolist()\n",
        "\n",
        "ner_ComboData = []\n",
        "for i in ner:\n",
        "    for j in i.ents:\n",
        "        ner_ComboData.append((j.text, j.label_))\n",
        "\n",
        "df_ner = pd.DataFrame(ner_ComboData, columns=['text', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2eqgSPOgqjh",
        "outputId": "6df2a869-b928-4edc-f402-9e9302f6a2cd"
      },
      "source": [
        "df_ner.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pdx</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>factsguide society</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tomorrow</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the next school year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   text label\n",
              "0                   pdx   GPE\n",
              "1    factsguide society   ORG\n",
              "2              tomorrow  DATE\n",
              "3  the next school year  DATE\n",
              "4              the year  DATE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_1DssH4gqjj",
        "outputId": "4ae45237-d004-468a-9451-b6706b5dcf4f"
      },
      "source": [
        "df_ner['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DATE           10800\n",
              "PERSON          6802\n",
              "GPE             5500\n",
              "ORG             5443\n",
              "TIME            2297\n",
              "NORP            1741\n",
              "CARDINAL        1122\n",
              "ORDINAL          637\n",
              "LOC              312\n",
              "FAC              301\n",
              "PRODUCT          245\n",
              "EVENT            132\n",
              "WORK_OF_ART       70\n",
              "LANGUAGE          37\n",
              "LAW               12\n",
              "QUANTITY          10\n",
              "MONEY              7\n",
              "PERCENT            3\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g72RGZqNgqjk"
      },
      "source": [
        "df_ner_person = df_ner.loc[df_ner['label'] == 'PERSON', ['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "cfoiQWVIgqjk",
        "outputId": "4e936a56-84f8-4f4d-85c2-128c173f43a5"
      },
      "source": [
        "df_ner_person['text'].value_counts().head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bing bong            107\n",
              "obama                 80\n",
              "hillary               62\n",
              "hu                    58\n",
              "orlando               33\n",
              "christina grimmie     32\n",
              "jesus                 30\n",
              "lebron                29\n",
              "donald                26\n",
              "clinton               22\n",
              "god                   22\n",
              "michelle obama        20\n",
              "bernie                20\n",
              "carl paladino         20\n",
              "donald trump          20\n",
              "ali                   18\n",
              "jo cox                18\n",
              "karen iqbal galib     17\n",
              "starkes gewitter      17\n",
              "sun                   17\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJILt-SNgqjk"
      },
      "source": [
        "Задание 2.\n",
        "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру.\n",
        "\n",
        "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Cs2Hv-gqjk",
        "outputId": "55ee6b53-50c8-4628-caea-6ac7ddb2337e"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\a.kraev\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu2zf6Uqgqjl",
        "outputId": "531473e8-5d9f-47aa-ce84-628c7fd45030"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     C:\\Users\\a.kraev\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvW90Gyygqjl",
        "outputId": "ac72d2cc-9809-475e-b543-894d3c60daf4"
      },
      "source": [
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\a.kraev\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\words.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvv415TAgqjl"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvWNubuPgqjl",
        "outputId": "4356f4bc-291a-4ac5-9ddb-ec3130f8bc3b"
      },
      "source": [
        "token_list = list()\n",
        "\n",
        "for list__ in df['tweet_token']:\n",
        "    for list_ in list__:\n",
        "        token_list.append(list_)\n",
        "\n",
        "len(token_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "579564"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bd7u-grgqjm"
      },
      "source": [
        "tags = nltk.pos_tag(token_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErMbYifVgqjm"
      },
      "source": [
        "chunk = nltk.ne_chunk(tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01K_VNm_gqjm",
        "outputId": "477c062e-a474-4fa6-966e-93827187e77b"
      },
      "source": [
        "ner_list = ner.tolist()\n",
        "\n",
        "ner_ComboData = []\n",
        "for one_chunk in chunk:\n",
        "    #print(one_chunk)\n",
        "    try:\n",
        "        ner_ComboData.append((one_chunk[0], one_chunk[1]))\n",
        "    except Exception:\n",
        "        print(one_chunk)\n",
        "\n",
        "df_ner = pd.DataFrame(ner_ComboData, columns=['text', 'label'])\n",
        "df_ner.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(ORGANIZATION tonightI/JJ)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when</td>\n",
              "      <td>WRB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>father</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is</td>\n",
              "      <td>VBZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dysfunctional</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>is</td>\n",
              "      <td>VBZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>so</td>\n",
              "      <td>RB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>selfish</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>he</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>drags</td>\n",
              "      <td>VBZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>his</td>\n",
              "      <td>PRP$</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>kids</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>into</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>his</td>\n",
              "      <td>PRP$</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>dysfunction</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>run</td>\n",
              "      <td>VB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>thanks</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>for</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>lyft</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>credit</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             text label\n",
              "0            when   WRB\n",
              "1          father    NN\n",
              "2              is   VBZ\n",
              "3   dysfunctional    JJ\n",
              "4             and    CC\n",
              "5              is   VBZ\n",
              "6              so    RB\n",
              "7         selfish    JJ\n",
              "8              he   PRP\n",
              "9           drags   VBZ\n",
              "10            his  PRP$\n",
              "11           kids   NNS\n",
              "12           into    IN\n",
              "13            his  PRP$\n",
              "14    dysfunction    NN\n",
              "15            run    VB\n",
              "16         thanks   NNS\n",
              "17            for    IN\n",
              "18           lyft    JJ\n",
              "19         credit    NN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3CzY39Agqjm",
        "outputId": "17f0d51d-ed27-4c20-fd8f-f3745a6e10ed"
      },
      "source": [
        "df_ner['label'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['WRB', 'NN', 'VBZ', 'JJ', 'CC', 'RB', 'PRP', 'PRP$', 'NNS', 'IN',\n",
              "       'VB', 'MD', 'VBP', 'VBN', 'VBD', 'PDT', 'DT', 'VBG', 'TO', 'WP',\n",
              "       'EX', 'RP', 'NNP', 'WDT', 'JJR', 'CD', 'JJS', 'FW', 'UH', 'RBS',\n",
              "       'RBR', \"''\", 'WP$', 'NNPS', 'POS', '$'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM1uqRJtgqjn",
        "outputId": "833438c0-8ecf-4419-85ad-150ee12d8940"
      },
      "source": [
        "df_ner['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN      146836\n",
              "JJ       72597\n",
              "IN       51408\n",
              "NNS      36138\n",
              "RB       32776\n",
              "VB       30276\n",
              "VBP      30225\n",
              "PRP      27729\n",
              "DT       27618\n",
              "VBZ      19809\n",
              "VBG      16741\n",
              "TO       15358\n",
              "PRP$     12109\n",
              "VBD      11793\n",
              "CC       10241\n",
              "VBN       9199\n",
              "MD        7315\n",
              "WRB       4379\n",
              "WP        3192\n",
              "RP        3019\n",
              "CD        1770\n",
              "JJS       1734\n",
              "JJR       1646\n",
              "WDT       1566\n",
              "PDT       1138\n",
              "RBR        881\n",
              "FW         600\n",
              "EX         570\n",
              "NNP        399\n",
              "RBS        334\n",
              "UH         126\n",
              "NNPS        15\n",
              "''          11\n",
              "WP$         10\n",
              "POS          4\n",
              "$            1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYBUn0XVgqjn"
      },
      "source": [
        "df_ner_pereson = df_ner.loc[df_ner['label'] == 'NNP', 'text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV3oQzVYgqjn",
        "outputId": "5c2d0072-eb32-401b-8bcf-876f8bd5136a"
      },
      "source": [
        "df_ner_pereson.value_counts().head(40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "xxx             75\n",
              "xoxo            29\n",
              "xx              28\n",
              "xenophobia      19\n",
              "youtuber        16\n",
              "october          9\n",
              "kinky            9\n",
              "xmas             8\n",
              "september        7\n",
              "xboxe            6\n",
              "zen              6\n",
              "xd               6\n",
              "xo               6\n",
              "xbox             5\n",
              "yay              3\n",
              "yogi             3\n",
              "xc               3\n",
              "zionazis         3\n",
              "xxxx             3\n",
              "kickstaer        2\n",
              "xhaka            2\n",
              "kaika            2\n",
              "xterra           2\n",
              "yoga             2\n",
              "november         2\n",
              "zurich           2\n",
              "xxxxx            2\n",
              "michigan         2\n",
              "xtremeairk       2\n",
              "sober            2\n",
              "justinbieber     2\n",
              "yesyou           2\n",
              "lbgt             2\n",
              "zoro             2\n",
              "oxford           2\n",
              "june             2\n",
              "zealand          2\n",
              "zrich            2\n",
              "keshi            2\n",
              "lifemember       1\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPkKmGdUgqjn"
      },
      "source": [
        "document = df['clean_tweet'].to_string()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZF8ufLEgqjn",
        "outputId": "23ac1866-2424-4a2c-c243-eab2cd15064f"
      },
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('tonightI', 'ORGANIZATION')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts8oBXAlgqjo"
      },
      "source": [
        "# Задание 3.\n",
        "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8Q-3juvgqjo"
      },
      "source": [
        "spacy, nltk не распознала ни персоны, ни организации. nltk их классифицировала только как существительные."
      ]
    }
  ]
}