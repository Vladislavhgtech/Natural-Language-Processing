{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vitto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\vitto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\vitto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000)\n",
    "С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n",
    "Повторим шаги из заданий 1 и 2, используя библиотеку nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = pd.read_pickle('result.pkl')\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wheelchair vans</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdx</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the next school year</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word     ner\n",
       "0       wheelchair vans     ORG\n",
       "1                   pdx     ORG\n",
       "2                bihday  PERSON\n",
       "3              tomorrow    DATE\n",
       "4  the next school year    DATE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df['NER'] = processed_df['clean_tweet'].apply(lambda x:  nlp(x))\n",
    "\n",
    "ner = processed_df['NER'].tolist()\n",
    "\n",
    "NER = []\n",
    "for doc in ner:\n",
    "    for ent in doc.ents:\n",
    "        NER.append((ent.text, ent.label_))\n",
    "\n",
    "df_ner = pd.DataFrame(NER, columns=['word', 'ner'])\n",
    "df_ner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE           11514\n",
       "PERSON          8000\n",
       "ORG             5562\n",
       "GPE             4573\n",
       "TIME            2034\n",
       "NORP            1451\n",
       "CARDINAL        1091\n",
       "ORDINAL          648\n",
       "FAC              302\n",
       "LOC              217\n",
       "EVENT            149\n",
       "PRODUCT           60\n",
       "LANGUAGE          42\n",
       "QUANTITY          34\n",
       "WORK_OF_ART       27\n",
       "LAW               22\n",
       "MONEY              8\n",
       "PERCENT            3\n",
       "Name: ner, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_ner = df_ner.ner.value_counts().head(20)\n",
    "top_20_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hea                                                        119\n",
       "hu                                                          87\n",
       "blur sun                                                    55\n",
       "bihday                                                      47\n",
       "feminismiscancer feminismisterrorism feminismmuktbharat     40\n",
       "christina grimmie                                           38\n",
       "hillary                                                     37\n",
       "sikh temple                                                 28\n",
       "tgif ff                                                     26\n",
       "don                                                         24\n",
       "clinton                                                     21\n",
       "detoxdiet altwaystoheal                                     21\n",
       "jo cox                                                      20\n",
       "ripchristina                                                20\n",
       "carl paladino                                               19\n",
       "karen iqbal                                                 17\n",
       "regrann                                                     17\n",
       "donald trump                                                16\n",
       "moon                                                        15\n",
       "michelle                                                    15\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_pers = df_ner.loc[df_ner['ner'] == 'PERSON']\n",
    "\n",
    "top_20_pers = top_20_pers.word.value_counts().head(20)\n",
    "top_20_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bong bing           107\n",
       "app                  84\n",
       "gop                  77\n",
       "islam                58\n",
       "house                46\n",
       "social analytics     40\n",
       "nba                  39\n",
       "usa                  35\n",
       "amazon               32\n",
       "sta                  31\n",
       "sma                  30\n",
       "cnn                  28\n",
       "euro                 27\n",
       "fed                  25\n",
       "ios                  23\n",
       "eu                   22\n",
       "fbi                  21\n",
       "sun                  20\n",
       "bogota colombia      20\n",
       "congress             19\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_org = df_ner.loc[df_ner['ner'] == 'ORG']\n",
    "\n",
    "top_20_org = top_20_org.word.value_counts().head(20)\n",
    "top_20_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру.\n",
    "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(father, RBR), (dysfunctional, JJ), (selfish,...\n",
       "1    [(thanks, NNS), (lyft, VBP), (credit, NN), (ca...\n",
       "2                        [(bihday, NN), (majesty, NN)]\n",
       "3    [(model, NN), (love, NN), (u, JJ), (take, VB),...\n",
       "4    [(factsguide, JJ), (society, NN), (now, RB), (...\n",
       "Name: tagged, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = set(string.punctuation)\n",
    "stop_words = set(get_stop_words(\"en\"))\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = re.sub('@[\\w]*', ' ', txt)\n",
    "    txt = re.sub(r'[^\\w\\s]',' ', txt)\n",
    "    txt = re.sub(r'[0-9]+', ' ', txt)\n",
    "    txt = re.sub('\\n', ' ', txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = [word for word in txt.split() if word not in exclude if word not in stop_words]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "\n",
    "processed_df['tagged'] = processed_df['tweet'].apply(preprocess_text).apply(\n",
    "    lambda x: nltk.pos_tag(nltk.word_tokenize(x)) \n",
    ")\n",
    "\n",
    "processed_df['tagged'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in processed_df['tagged'].tolist():\n",
    "    corpus.extend(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442180"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = {(' '.join(c[0] for c in chunk), chunk.label()) \n",
    "    for chunk in nltk.ne_chunk(corpus) \n",
    "    if hasattr(chunk, 'label')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('adriÃ', 'ORGANIZATION'),\n",
       " ('aldilÃ', 'ORGANIZATION'),\n",
       " ('anaÃ', 'ORGANIZATION'),\n",
       " ('anchequestoÃ', 'ORGANIZATION'),\n",
       " ('andrÃ', 'ORGANIZATION'),\n",
       " ('areÂ', 'ORGANIZATION'),\n",
       " ('asÃ', 'ORGANIZATION'),\n",
       " ('atÂ', 'ORGANIZATION'),\n",
       " ('babalargÃ¼nÃ¼', 'ORGANIZATION'),\n",
       " ('befÄ', 'ORGANIZATION'),\n",
       " ('bellÃ', 'ORGANIZATION'),\n",
       " ('beyoncÃ', 'ORGANIZATION'),\n",
       " ('beyoÄ', 'ORGANIZATION'),\n",
       " ('bonnejournÃ', 'ORGANIZATION'),\n",
       " ('braggingÂ', 'ORGANIZATION'),\n",
       " ('brÃ¼ssel', 'ORGANIZATION'),\n",
       " ('cafÃ', 'ORGANIZATION'),\n",
       " ('canÂ', 'ORGANIZATION'),\n",
       " ('castaÃ', 'ORGANIZATION'),\n",
       " ('catedraldesaldezipaquirÃ', 'ORGANIZATION'),\n",
       " ('chloÃ', 'ORGANIZATION'),\n",
       " ('chÃ', 'ORGANIZATION'),\n",
       " ('citlaltÃ', 'ORGANIZATION'),\n",
       " ('comounniÃ', 'ORGANIZATION'),\n",
       " ('coolÂ', 'ORGANIZATION'),\n",
       " ('costeÃ', 'ORGANIZATION'),\n",
       " ('crÃªpes', 'ORGANIZATION'),\n",
       " ('cumpleaÃ', 'ORGANIZATION'),\n",
       " ('deberÃ de', 'ORGANIZATION'),\n",
       " ('depresiÃ³n', 'ORGANIZATION'),\n",
       " ('diplomalÄ', 'ORGANIZATION'),\n",
       " ('diversiÃ³n', 'ORGANIZATION'),\n",
       " ('divulgaÃ Ã', 'ORGANIZATION'),\n",
       " ('domÃ', 'ORGANIZATION'),\n",
       " ('donÂ', 'ORGANIZATION'),\n",
       " ('doppelgÃ', 'ORGANIZATION'),\n",
       " ('dÃ¼Å Ã¼Å', 'ORGANIZATION'),\n",
       " ('eskiÅ', 'ORGANIZATION'),\n",
       " ('espaÃ', 'ORGANIZATION'),\n",
       " ('estÃ', 'ORGANIZATION'),\n",
       " ('exposÃ', 'ORGANIZATION'),\n",
       " ('fatherÃ Â', 'ORGANIZATION'),\n",
       " ('felicitÃ', 'ORGANIZATION'),\n",
       " ('fiancÃ', 'ORGANIZATION'),\n",
       " ('foiinÃ', 'ORGANIZATION'),\n",
       " ('forÃ', 'ORGANIZATION'),\n",
       " ('fpÃ', 'ORGANIZATION'),\n",
       " ('frÃ', 'ORGANIZATION'),\n",
       " ('fÃªte', 'ORGANIZATION'),\n",
       " ('gadaÃ', 'ORGANIZATION'),\n",
       " ('garÃ', 'ORGANIZATION'),\n",
       " ('gdaÅ', 'ORGANIZATION'),\n",
       " ('glÃ¼ck', 'ORGANIZATION'),\n",
       " ('godÂ Â', 'ORGANIZATION'),\n",
       " ('goodbyeÂ', 'ORGANIZATION'),\n",
       " ('gÃ¼mbet', 'ORGANIZATION'),\n",
       " ('happyÂ', 'ORGANIZATION'),\n",
       " ('hiÃ', 'ORGANIZATION'),\n",
       " ('husbandÂ', 'ORGANIZATION'),\n",
       " ('ilustraciÃ³n', 'ORGANIZATION'),\n",
       " ('indonesiafoheworldÂ', 'ORGANIZATION'),\n",
       " ('inglÃ', 'ORGANIZATION'),\n",
       " ('inspiraÃ Ã', 'ORGANIZATION'),\n",
       " ('instaviÃ', 'ORGANIZATION'),\n",
       " ('isleÃ', 'ORGANIZATION'),\n",
       " ('isÂ', 'ORGANIZATION'),\n",
       " ('itÂ', 'ORGANIZATION'),\n",
       " ('kesÃ', 'ORGANIZATION'),\n",
       " ('knaackÂ', 'ORGANIZATION'),\n",
       " ('kohlisoonÂ', 'ORGANIZATION'),\n",
       " ('koithÃ', 'ORGANIZATION'),\n",
       " ('koÅ', 'ORGANIZATION'),\n",
       " ('kwanzaaÂ', 'ORGANIZATION'),\n",
       " ('kÃ', 'ORGANIZATION'),\n",
       " ('kÃ²', 'ORGANIZATION'),\n",
       " ('laclÃ', 'ORGANIZATION'),\n",
       " ('lapeÃ', 'ORGANIZATION'),\n",
       " ('lifeÂ Â', 'ORGANIZATION'),\n",
       " ('lightningÂ', 'ORGANIZATION'),\n",
       " ('logroÃ', 'ORGANIZATION'),\n",
       " ('loselbssaveÂ', 'ORGANIZATION'),\n",
       " ('magnÃ', 'ORGANIZATION'),\n",
       " ('mamadeniÃ', 'ORGANIZATION'),\n",
       " ('marschfÃ¼rjesus', 'ORGANIZATION'),\n",
       " ('mayoncÃ', 'ORGANIZATION'),\n",
       " ('mayÃ', 'ORGANIZATION'),\n",
       " ('mccafÃ', 'ORGANIZATION'),\n",
       " ('mesutÃ', 'ORGANIZATION'),\n",
       " ('metroÅ', 'ORGANIZATION'),\n",
       " ('miÅ', 'ORGANIZATION'),\n",
       " ('moanaÂ', 'ORGANIZATION'),\n",
       " ('montrÃ', 'ORGANIZATION'),\n",
       " ('naÃ', 'ORGANIZATION'),\n",
       " ('neuchÃ', 'ORGANIZATION'),\n",
       " ('newsÂ', 'ORGANIZATION'),\n",
       " ('neÃ³n', 'ORGANIZATION'),\n",
       " ('novitÃ', 'ORGANIZATION'),\n",
       " ('oilÂ', 'ORGANIZATION'),\n",
       " ('ontiatÃ', 'ORGANIZATION'),\n",
       " ('oÂ²breakthroughÂ', 'ORGANIZATION'),\n",
       " ('oÅ Ä', 'ORGANIZATION'),\n",
       " ('phÃ', 'ORGANIZATION'),\n",
       " ('pinÃ', 'ORGANIZATION'),\n",
       " ('pizzadÃ', 'ORGANIZATION'),\n",
       " ('plaÅ', 'ORGANIZATION'),\n",
       " ('pokÃ', 'ORGANIZATION'),\n",
       " ('poussiÂ Â', 'ORGANIZATION'),\n",
       " ('poÃ', 'ORGANIZATION'),\n",
       " ('quÃ', 'ORGANIZATION'),\n",
       " ('rainingÂ', 'ORGANIZATION'),\n",
       " ('rainÂ', 'ORGANIZATION'),\n",
       " ('rosÃ', 'ORGANIZATION'),\n",
       " ('rÃ²om', 'ORGANIZATION'),\n",
       " ('sabÃ', 'ORGANIZATION'),\n",
       " ('schÃ', 'ORGANIZATION'),\n",
       " ('skellefteÃ', 'ORGANIZATION'),\n",
       " ('soufflÃ', 'ORGANIZATION'),\n",
       " ('stormÂ', 'ORGANIZATION'),\n",
       " ('sueÃ', 'ORGANIZATION'),\n",
       " ('sunflowerÂ', 'ORGANIZATION'),\n",
       " ('szczÄ Å', 'ORGANIZATION'),\n",
       " ('sÃ³ria', 'ORGANIZATION'),\n",
       " ('tejiendosueÃ', 'ORGANIZATION'),\n",
       " ('thatÂ', 'ORGANIZATION'),\n",
       " ('todayÂ', 'ORGANIZATION'),\n",
       " ('todayÃ', 'ORGANIZATION'),\n",
       " ('townÂ²', 'ORGANIZATION'),\n",
       " ('travelÂ', 'ORGANIZATION'),\n",
       " ('turÂ', 'ORGANIZATION'),\n",
       " ('twÃ¼tters', 'ORGANIZATION'),\n",
       " ('tÃ¼sh', 'ORGANIZATION'),\n",
       " ('viÃ', 'ORGANIZATION'),\n",
       " ('vysoÄ', 'ORGANIZATION'),\n",
       " ('weatherÂ', 'ORGANIZATION'),\n",
       " ('whatÂ', 'ORGANIZATION'),\n",
       " ('whiteaddictÂ', 'ORGANIZATION'),\n",
       " ('wilÃ', 'ORGANIZATION'),\n",
       " ('wiÄ', 'ORGANIZATION'),\n",
       " ('wunderschÃ', 'ORGANIZATION'),\n",
       " ('zlÃ¼Ä', 'ORGANIZATION'),\n",
       " ('zÃ¼rich', 'ORGANIZATION'),\n",
       " ('Â', 'PERSON'),\n",
       " ('Â Â', 'PERSON'),\n",
       " ('ÂµÂ Â²Â', 'ORGANIZATION'),\n",
       " ('Ã Â', 'PERSON'),\n",
       " ('Ã¼molmadanasla', 'ORGANIZATION'),\n",
       " ('Ð Ð', 'PERSON'),\n",
       " ('Ð²Ð¾Ñ Ð¾Ð½ÐµÐ', 'PERSON'),\n",
       " ('ÐµÐ¼ÐºÐ', 'ORGANIZATION'),\n",
       " ('ÐºÐ¾Ð½Ñ', 'ORGANIZATION'),\n",
       " ('Ð¼Ð Ð¹Ñ', 'PERSON'),\n",
       " ('Ñ Ð¾Ñ', 'PERSON'),\n",
       " ('Ø³Ù Ù', 'PERSON')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER работает медленно и чистота информации оставляет желать лучшего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
